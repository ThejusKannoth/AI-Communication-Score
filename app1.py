# -*- coding: utf-8 -*-
"""app1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jeTFa29pxmDIW99aXO5LQTs_Z4LW0tPT
"""

import re
from typing import List, Dict, Any

import numpy as np
import streamlit as st
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

from sentence_transformers import SentenceTransformer, util

st.set_page_config(page_title="Communication Scorer", layout="centered")

# Load models
@st.cache_resource
def get_embedding_model():
    return SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

@st.cache_resource
def get_sentiment_analyzer():
    return SentimentIntensityAnalyzer()

embedder = get_embedding_model()
sent_analyzer = get_sentiment_analyzer()

# Rubric configuration
CRITERIA = [
    {
        "id": "content_structure",
        "name": "Content & Structure",
        "weight": 40,
        "description": (
            "A short self introduction that clearly covers name, age, "
            "class/school, family, hobbies or interests, and ends with a polite closing."
        ),
        "min_words": 60,
        "max_words": 180,
        "must_groups": {
            "name": ["my name is", "myself"],
            "age": ["years old"],
            "class_school": ["class", "grade", "standard", "school"],
            "family": ["family", "mother", "father", "parents"],
            "hobbies": ["hobby", "hobbies", "i like to", "i enjoy", "my favourite", "my favorite"],
        },
        "good_groups": {
            "origin": ["i am from", "i'm from"],
            "fun_fact": ["fun fact", "one thing about me", "something people don't know"],
            "strengths_achievements": ["achievement", "i won", "i got first", "award", "prize"],
        },
        "greetings": ["hello", "hi", "good morning", "good afternoon", "good evening"],
        "closings": ["thank you", "thanks for listening", "thank you for listening"]
    },
    {
        "id": "speech_rate",
        "name": "Speech Rate (proxy by length)",
        "weight": 10,
        "description": "Comfortable speech rate for a short self introduction (80–140 words).",
        "min_words": 80,
        "max_words": 140,
    },
    {
        "id": "language_grammar",
        "name": "Language & Grammar",
        "weight": 20,
        "description": "Uses simple but correct sentences and reasonably rich vocabulary.",
    },
    {
        "id": "clarity",
        "name": "Clarity (Filler words)",
        "weight": 15,
        "description": "Minimizes filler words like 'um', 'uh', 'you know', 'like'.",
    },
    {
        "id": "engagement",
        "name": "Engagement / Positivity",
        "weight": 15,
        "description": "Tone is positive and enthusiastic.",
    },
]


# Helper functions
def preprocess(text: str) -> str:
    # Lowercase and collapse whitespace
    return re.sub(r"\s+", " ", text.strip().lower())


def tokenize(text: str) -> List[str]:
    return re.findall(r"\b\w+\b", text.lower())


def word_count(text: str) -> int:
    return len(tokenize(text))


def length_score(num_words: int, min_words: int, max_words: int) -> float:
    """Triangular scoring: 1 inside [min,max], decays to 0 outside."""
    if num_words <= 0:
        return 0.0
    if min_words is None or max_words is None:
        return 1.0

    if min_words <= num_words <= max_words:
        return 1.0

    # Define a max distance after which score is 0 (half range as buffer)
    buffer = max(1, (max_words - min_words) // 2)
    if num_words < min_words:
        dist = min_words - num_words
    else:
        dist = num_words - max_words

    if dist >= buffer:
        return 0.0
    return max(0.0, 1.0 - dist / buffer)


def group_presence_score(text: str, groups: Dict[str, List[str]]) -> (float, List[str]):
    found_groups = []
    for group_name, patterns in groups.items():
        if any(pat in text for pat in patterns):
            found_groups.append(group_name)
    if not groups:
        return 1.0, []
    score = len(found_groups) / len(groups)
    return score, found_groups


def ttr_score(text: str) -> float:
    tokens = tokenize(text)
    if not tokens:
        return 0.0
    unique_tokens = set(tokens)
    ttr = len(unique_tokens) / len(tokens)
    if ttr >= 0.9:
        return 1.0
    elif ttr >= 0.7:
        return 0.8
    elif ttr >= 0.5:
        return 0.6
    elif ttr >= 0.3:
        return 0.4
    else:
        return 0.2


def filler_score(text: str):
    fillers = ["um", "uh", "you know", "like", "sort of", "kind of", "so yeah"]
    words = tokenize(text)
    n_words = len(words)
    lowered = text.lower()
    count = 0
    for f in fillers:
        if " " in f:
            # phrase
            count += lowered.count(f)
        else:
            count += sum(1 for w in words if w == f)

    if n_words == 0:
        return 0.0, 0, 0.0

    per_100 = count / n_words * 100

    if per_100 <= 3:
        score = 1.0
    elif per_100 <= 6:
        score = 0.8
    elif per_100 <= 9:
        score = 0.6
    elif per_100 <= 12:
        score = 0.4
    else:
        score = 0.2

    return score, count, per_100


def sentiment_score(text: str) -> float:
    if not text.strip():
        return 0.0
    s = sent_analyzer.polarity_scores(text)
    compound = s["compound"]  # -1..1
    return (compound + 1) / 2  # 0..1


def semantic_similarity(a: str, b: str) -> float:
    if not a.strip() or not b.strip():
        return 0.0
    emb = embedder.encode([a, b], convert_to_tensor=True)
    sim = util.cos_sim(emb[0], emb[1]).item()

    return float((sim + 1) / 2)  # force into 0..1


# Scoring per criterion
def score_transcript(transcript: str) -> Dict[str, Any]:
    raw_text = transcript
    text = preprocess(transcript)
    n_words = word_count(transcript)

    results = []
    total_points = 0.0
    total_weight = sum(c["weight"] for c in CRITERIA)

    for c in CRITERIA:
        cid = c["id"]
        w = c["weight"]
        desc = c["description"]
        details = {}
        crit_score_01 = 0.0  # normalized 0..1

        if cid == "content_structure":
            must_score, must_found = group_presence_score(text, c["must_groups"])
            good_score, good_found = group_presence_score(text, c["good_groups"])
            len_score_val = length_score(n_words, c["min_words"], c["max_words"])
            greeting_present = any(g in text for g in c["greetings"])
            closing_present = any(cl in text for cl in c["closings"])
            greet_closing_bonus = 0.0
            if greeting_present:
                greet_closing_bonus += 0.1
            if closing_present:
                greet_closing_bonus += 0.1
            greet_closing_bonus = min(greet_closing_bonus, 0.2)

            sem = semantic_similarity(raw_text, desc)

            crit_score_01 = (
                0.6 * must_score
                + 0.15 * good_score
                + 0.15 * len_score_val
                + 0.1 * sem
                + greet_closing_bonus
            )
            crit_score_01 = float(max(0.0, min(1.0, crit_score_01)))

            details.update(
                {
                    "must_have_found": must_found,
                    "good_to_have_found": good_found,
                    "length_score": len_score_val,
                    "semantic_similarity": sem,
                    "greeting_present": greeting_present,
                    "closing_present": closing_present,
                }
            )

        elif cid == "speech_rate":
            len_score_val = length_score(n_words, c["min_words"], c["max_words"])
            crit_score_01 = len_score_val
            details.update({"length_score": len_score_val, "target_range": "80–140 words"})

        elif cid == "language_grammar":
            ttr = ttr_score(text)
            sem = semantic_similarity(raw_text, desc)
            crit_score_01 = 0.7 * ttr + 0.3 * sem
            crit_score_01 = float(max(0.0, min(1.0, crit_score_01)))
            details.update({"ttr_score": ttr, "semantic_similarity": sem})

        elif cid == "clarity":
            cl_score, filler_count, per_100 = filler_score(text)
            crit_score_01 = cl_score
            details.update(
                {"filler_count": filler_count, "fillers_per_100_words": per_100}
            )

        elif cid == "engagement":
            sent = sentiment_score(raw_text)
            crit_score_01 = sent
            details.update({"sentiment_normalized": sent})

        crit_points = crit_score_01 * w
        total_points += crit_points

        results.append(
            {
                "id": cid,
                "name": c["name"],
                "weight": w,
                "score": round(crit_points, 2),
                "max_points": w,
                "percentage": round(crit_points / w * 100, 1) if w > 0 else 0.0,
                "feedback": "",
                "details": details,
            }
        )

    # Simple feedback text generation
    for r in results:
        cid = r["id"]
        pct = r["percentage"]
        fb_parts = []
        if pct >= 85:
            fb_parts.append("Excellent on this criterion.")
        elif pct >= 60:
            fb_parts.append("Good, but there is room for improvement.")
        else:
            fb_parts.append("Needs significant improvement on this criterion.")

        if cid == "content_structure":
            d = r["details"]
            missing_must = set(CRITERIA[0]["must_groups"].keys()) - set(d["must_have_found"])
            if missing_must:
                fb_parts.append("Missing key info: " + ", ".join(sorted(missing_must)))
            if not d["greeting_present"]:
                fb_parts.append("Consider starting with a simple greeting (e.g., 'Hello everyone').")
            if not d["closing_present"]:
                fb_parts.append("End with a closing line like 'Thank you for listening.'")
        elif cid == "speech_rate":
            fb_parts.append(
                f"Your transcript has {n_words} words; aim for about 80–140 words for a comfortable pace."
            )
        elif cid == "language_grammar":
            fb_parts.append("Try to use a mix of simple and slightly varied vocabulary.")
        elif cid == "clarity":
            d = r["details"]
            fb_parts.append(
                f"We detected {d['filler_count']} filler words (~{d['fillers_per_100_words']:.1f} per 100 words)."
            )
        elif cid == "engagement":
            fb_parts.append("Maintain a positive and confident tone throughout.")

        r["feedback"] = " ".join(fb_parts)

    overall_score = round(total_points / total_weight * 100, 1) if total_weight > 0 else 0.0

    return {
        "overall_score": overall_score,
        "word_count": n_words,
        "criteria": results,
    }


# Streamlit UI


st.title("Self-Introduction Scorer")
st.write(
    "Paste a **transcript of a short self-introduction** below. "
    "The tool will score it (0–100) using the rubric and show per-criterion feedback."
)

sample = (
    "Hello everyone, myself Muskan, studying in class 8th B section from Christ Public School. "
    "I am 13 years old. I live with my family. There are 3 people in my family, me, my mother and my father. "
    "One special thing about my family is that they are very kind hearted to everyone and soft spoken. "
    "One thing I really enjoy is playing cricket and taking wickets. "
    "A fun fact about me is that I see in the mirror and talk to myself. "
    "One thing people don't know about me is that I once stole a toy from one of my cousins. "
    "My favorite subject is science because it is very interesting. "
    "Through science I can explore the whole world and make discoveries and improve the lives of others. "
    "Thank you for listening."
)


if "transcript_text" not in st.session_state:
    st.session_state.transcript_text = sample

transcript = st.text_area(
    "Transcript text",
    height=250,
    key="transcript_text"
)

if st.button("Score"):
    if not transcript.strip():
        st.warning("Please paste a transcript first.")
    else:
        with st.spinner("Scoring transcript..."):
            result = score_transcript(transcript)

        st.subheader(f"Overall Score: {result['overall_score']} / 100")
        st.write(f"Word count: **{result['word_count']}**")

        st.subheader("Per-criterion breakdown")
        for c in result["criteria"]:
            st.markdown(f"### {c['name']} ({c['score']} / {c['max_points']})")
            st.progress(min(1.0, c["percentage"] / 100))
            st.write(f"Score: **{c['percentage']}%** (weight {c['weight']})")
            with st.expander("Details"):
                st.json(c["details"])
            st.write(c["feedback"])
            st.markdown("---")

st.caption("This is a prototype for the spoken communication rubric scorer.")